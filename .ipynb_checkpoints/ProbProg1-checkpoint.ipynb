{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ProbProg1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMwpNuihu+u98DQl6sT7p1+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s5Vv7-HaWYyh","colab_type":"text"},"source":["# Programowanie probabilistyczne w PyMC3"]},{"cell_type":"code","metadata":{"id":"ouIxN-sPuaTu","colab_type":"code","colab":{}},"source":["# Arviz służy do wizualizacji modeli Bayesowskich\n","!pip install arviz \n","!pip install 'pymc3==3.8'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmcwGrGtTnGc","colab_type":"code","colab":{}},"source":["\n","%matplotlib inline\n","import numpy as np\n","import theano\n","import theano.tensor as tt\n","import pymc3 as pm\n","import arviz\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.set_context('notebook')\n","plt.style.use('seaborn-darkgrid')\n","print('Running on PyMC3 v{}'.format(pm.__version__))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NXS0EuTiaJpK","colab_type":"text"},"source":["PyMC3 ma mnóstwo wbudowanych rozkładów prawdopodobieństw."]},{"cell_type":"code","metadata":{"id":"JlKgGwwzaOnz","colab_type":"code","colab":{}},"source":["print('\\n'.join([d for d in dir(pm.distributions) if d[0].isupper()]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJ9fq0THbFWy","colab_type":"text"},"source":["## Rzucanie monetą\n","\n","Załóżmy, że rzuciliśmy 50 razy monetą i 17 razy wypadła reszka. Jak ocenić szansę na wyrzucenie reszki? Czy możemy założyć, że szansa wypadnięcia orła i reszki jest taka sama?"]},{"cell_type":"code","metadata":{"id":"jT1AIk_VbJhg","colab_type":"code","colab":{}},"source":["n = 50\n","heads = 17\n","\n","niter = 2000\n","with pm.Model() as coin_model:\n","    # ustawiamy model\n","    p = pm.Uniform('p')\n","    # p = pm.Beta('p', alpha=2, beta=2)\n","    # p = pm.Beta('p', alpha=5, beta=1)\n","    y = pm.Binomial('y', n=n, p=p, observed=heads)\n","\n","\n","    trace = pm.sample(niter)\n","    # rysujemy wynik\n","    pm.traceplot(trace);\n","\n","    # Jakie prawdopodobieństwo wylosowania reszki jest najbardziej zgodne z danymi?\n","    p_map = pm.find_MAP()\n","    print(\"p MAP = \", p_map)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UytBFc0IdHkt","colab_type":"text"},"source":["Możemy zaobserwować co się dzieje przy wyborze różnych rozkładów dla `p`. Najbardziej zachowawczym wyborem jest rozkład równomierny (zakładamy, że każde prawdopodobieństwo wylosowania reszki jest tak samo możliwe). Możemy też ustawić inny rozkład, przykładowo `pm.Beta('p', alpha=2, beta=2)` który wyraża nasze przekonanie, że prawodopodobieństwa w okolicach 0.5 są bardziej prawdopodobne. Dlaczego akurat rozkład beta a nie jakikolwiek inny? Jeśli chcielibyśmy symulować model innymi metodami to rozkład beta byłby wygodny (to tzw. _conjugate prior_ dla rozkładu dwumianowego), ale dla metod typu Monte Carlo ma to mniejsze znaczenie. Nie ma żadnych wytycznych odnośnie tego który rozkład jest \"lepszy\". To, że któryś jest _conjugate prior_ oznacza głównie łatwiejsze obliczenia.\n","\n","Wybór rozkładu prawdopodobieństwa dla zmiennych które chcemy znaleźć jest szczególnie istotny gdy mamy mało danych. Jak danych jest sporo to i tak one przeważą."]},{"cell_type":"code","metadata":{"id":"I8e_5SAZ60gm","colab_type":"code","colab":{}},"source":["grid = np.linspace(0.0, 1.0, 100)\n","uniform_p = np.exp(pm.Uniform.dist().logp(grid))\n","beta22_p = np.exp(pm.Beta.dist(alpha=2, beta=2).logp(grid))\n","beta51_p = np.exp(pm.Beta.dist(alpha=5, beta=1).logp(grid))\n","\n","plt.plot(grid, uniform_p.eval(), 'r',\n","         grid, beta22_p.eval(), 'g',\n","         grid, beta51_p.eval(), 'b');"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQeWqdyl61oA","colab_type":"text"},"source":["\n","Weźmy teraz drugą monetę. Rzuciliśmy nią 50 razy i otrzymaliśmy 23 reszek."]},{"cell_type":"code","metadata":{"id":"HB0OftQjdWOE","colab_type":"code","colab":{}},"source":["n = 500\n","heads1 = 170\n","heads2 = 230\n","\n","niter = 2000\n","with pm.Model() as coin_model:\n","    # ustawiamy model\n","    p1 = pm.Uniform('p1')\n","    p2 = pm.Uniform('p2')\n","    y1 = pm.Binomial('y1', n=n, p=p1, observed=heads1)\n","    y2 = pm.Binomial('y2', n=n, p=p2, observed=heads2)\n","    diffp = pm.Deterministic('p1-p2', p1-p2)\n","\n","\n","    trace = pm.sample(niter)\n","    # rysujemy wynik\n","    pm.traceplot(trace);\n","    display(pm.summary(trace, var_names=['p1', 'p2', 'p1-p2']))\n","\n","    # Jakie prawdopodobieństwo wylosowania reszki jest najbardziej zgodne z danymi?\n","    p_map = pm.find_MAP()\n","    print(\"MAP = \", p_map)\n","\n","    # Jak ocenić szansę, że druga moneta ma większe prawodopodobieństwo wyrzucenia reszki?\n","    p1vals = trace.get_values('p1')\n","    p2vals = trace.get_values('p2')\n","    numvals = len(p1vals)\n","    counts = sum([1 for i in range(numvals) if p1vals[i] < p2vals[i]])\n","    print(\"p1 < p2? \", counts/numvals)\n","\n","\n","    # Jak ocenić szansę, że obie monety mają taką samą szansę wylosowania reszki?\n","    pm.plot_posterior(trace, var_names=['p1-p2'],\n","                      ref_val=0,\n","                      color='#00eeee');\n","\n","    \n","    pm.forestplot(trace, var_names=['p1',\n","                                    'p2',\n","                                    'p1-p2']);\n","\n","    \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3o-g_ae3WT_k","colab_type":"text"},"source":["## Prosty model regresji"]},{"cell_type":"code","metadata":{"id":"9zvZ5SoAWSGn","colab_type":"code","colab":{}},"source":["with pm.Model() as model_reg_simple:\n","    mu = pm.Normal('mu', mu=0, sigma=1)\n","    mup1 = mu+1 # transformacja zmiennej\n","    mum1 = pm.Deterministic('mu minus 1', mu - 1)\n","    obs = pm.Normal('obs', mu=mup1, sigma=1, observed=np.random.randn(100))\n","\n","    print(\"Zmienne losowe:\", model_reg_simple.basic_RVs)\n","    print(\"Zmienne losowe które obserwujemy: \", model_reg_simple.observed_RVs)\n","    print(\"Zmienne będące transformacjami innych: \", model_reg_simple.deterministics)\n","    print(\"Pozostałe zmienne: \", model_reg_simple.free_RVs)\n","\n","    trace = pm.sample(1000, tune=500)\n","    pm.traceplot(trace);\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b76omaQEaqbt","colab_type":"text"},"source":["Domyślnie dla rozkładów ciągłych stosowany jest algorytm NUTS, ale dostępne są też inne."]},{"cell_type":"code","metadata":{"id":"a5vM6RZfayTB","colab_type":"code","colab":{}},"source":["print('\\n'.join(m for m in dir(pm.step_methods) if m[0].isupper()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uLTUfJ1O1yi_","colab_type":"text"},"source":["## Analiza wypadków w kopalniach"]},{"cell_type":"code","metadata":{"id":"_PVaP-1j12lB","colab_type":"code","colab":{}},"source":["# Time series of recorded coal mining disasters in the UK from 1851 to 1962\n","disasters_data = np.array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n","                           3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n","                           2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n","                           1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n","                           0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n","                           3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n","                           0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n","year = np.arange(1851, 1962)\n","\n","plt.plot(year, disasters_data)\n","\n","with pm.Model() as model_mine:\n","\n","    switchpoint = pm.DiscreteUniform('switchpoint', lower=year.min(), upper=year.max())\n","    early_mean = pm.Exponential('early_mean', lam=1.)\n","    late_mean = pm.Exponential('late_mean', lam=1.)\n","\n","    # Allocate appropriate Poisson rates to years before and after current\n","    # switchpoint location\n","    rate = tt.switch(switchpoint >= year, early_mean, late_mean)\n","    \n","    disasters = pm.Poisson('disasters', rate, observed=disasters_data)\n","\n","    # Initial values for stochastic nodes\n","    start = {'early_mean': 2., 'late_mean': 3.}\n","    \n","    tr = pm.sample(2000, tune=500, start=start)\n","    pm.traceplot(tr)\n","\n","\n","pm.model_to_graphviz(model_mine)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KKy3aN3ZWhTh","colab_type":"text"},"source":["## Poziom randonu\n","\n","Zmierzono poziom radonu w domach w różnych hrabstwach aby sprawdzić, czy obecność piwnicy wpływa na poziom szkodliwego radonu.\n","\n","Za: https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/GLM-hierarchical.ipynb\n","oraz https://docs.pymc.io/notebooks/multilevel_modeling.html\n","\n","Co zakłada poniższy model? Spróbuj uzasadnić dlaczego współczynniki `b` przy niektórych hrabstrawach mają bardzo duże rozpiętości."]},{"cell_type":"code","metadata":{"id":"wX65avXL5d_f","colab_type":"code","colab":{}},"source":["print(pd.read_csv(pm.get_data('radon.csv')).columns)\n","\n","data = pd.read_csv(pm.get_data('radon.csv'))[['Unnamed: 0', 'county', 'county_code', 'region', 'floor', 'room', 'fips', 'Uppm', 'log_radon']]\n","data['log_radon'] = data['log_radon'].astype(theano.config.floatX)\n","county_names = data.county.unique()\n","county_idx = data.county_code.values\n","\n","display(data.loc[data['county_code'] == 81])\n","display(data.loc[data['county_code'] == 84])\n","\n","data.county = data.county.map(str.strip)\n","unique_counties = data.county.unique()\n","n_counties = len(unique_counties)\n","# county_lookup = dict(zip(mn_counties, range(len(unique_counties))))\n","\n","# county = srrs_mn['county_code'] = srrs_mn.county.replace(county_lookup).values\n","\n","print(n_counties)\n","display(data.describe())\n","\n","with pm.Model() as unpooled_model:\n","\n","    # Independent parameters for each county\n","    a = pm.Normal('a', 0, sigma=50, shape=n_counties)\n","    b = pm.Normal('b', 0, sigma=50, shape=n_counties)\n","\n","    # Model error\n","    eps = pm.HalfCauchy('eps', 5)\n","\n","    # Model prediction of radon level\n","    # a[county_idx] translates to a[0, 0, 0, 1, 1, ...],\n","    # we thus link multiple household measures of a county\n","    # to its coefficients.\n","    radon_est = a[county_idx] + b[county_idx]*data.floor.values\n","\n","    # Data likelihood\n","    y = pm.Normal('y', radon_est, sigma=eps, observed=data.log_radon)\n","\n","    trace = pm.sample(1000, tune=500)\n","    pm.traceplot(trace)\n","    summary = pm.summary(trace, var_names=['a', 'b', 'eps'])\n","    summary.sort_values(by=['r_hat'])\n","    display(summary)\n","\n","    pm.forestplot(trace, var_names=['a', 'b', 'eps'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIKJEc_XKDeq","colab_type":"text"},"source":["Można przedstawić kod jako model grafowy:"]},{"cell_type":"code","metadata":{"id":"ktnABLZNP03V","colab_type":"code","colab":{}},"source":["pm.model_to_graphviz(unpooled_model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ipZJsLyfFV0d","colab_type":"text"},"source":["### Model wielopoziomowy dla przykładu z radem"]},{"cell_type":"code","metadata":{"id":"gpwKEGRjFZb0","colab_type":"code","colab":{}},"source":["with pm.Model() as hierarchical_model:\n","    # Hyperpriors for group nodes\n","    mu_a = pm.Normal('mu_a', mu=0., sigma=100)\n","    sigma_a = pm.HalfNormal('sigma_a', 5.)\n","    mu_b = pm.Normal('mu_b', mu=0., sigma=100)\n","    sigma_b = pm.HalfNormal('sigma_b', 5.)\n","\n","    # Intercept for each county, distributed around group mean mu_a\n","    # Above we just set mu and sd to a fixed value while here we\n","    # plug in a common group distribution for all a and b (which are\n","    # vectors of length n_counties).\n","    a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=n_counties)\n","    # Intercept for each county, distributed around group mean mu_a\n","    b = pm.Normal('b', mu=mu_b, sigma=sigma_b, shape=n_counties)\n","\n","    # Model error\n","    eps = pm.HalfCauchy('eps', 5.)\n","\n","    radon_est = a[county_idx] + b[county_idx]*data.floor.values\n","\n","    # Data likelihood\n","    radon_like = pm.Normal('radon_like', mu=radon_est,\n","                           sigma=eps, observed=data.log_radon)\n","    \n","    hierarchical_trace = pm.sample(2000, tune=2000, target_accept=.9)\n","\n","    pm.traceplot(hierarchical_trace,\n","                 var_names=['mu_a', 'mu_b', 'sigma_a', 'sigma_b', 'eps'])\n","    display(pm.summary(hierarchical_trace, var_names=['mu_a', 'mu_b', 'eps']))\n","\n","    pm.forestplot(hierarchical_trace, var_names=['mu_a', 'mu_b', 'sigma_a', 'sigma_b', 'eps'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLXynkgFP3A2","colab_type":"text"},"source":["Model grafowy:"]},{"cell_type":"code","metadata":{"id":"biwvHORLP5SF","colab_type":"code","colab":{}},"source":["pm.model_to_graphviz(hierarchical_model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NeuC2Ay6D1td","colab_type":"text"},"source":["Możemy wykorzystać dodatkowe informacje które zostały zebrane, na przykład poziom uranu. W poprzednim przykładzie zakładaliśmy, że różnice w rozkładach średniego poziomu i efektu występowania piwnicy pomiędzy hrabstwami są zupełnie losowe. W kolejnym modelu badamy związek pomiędzy zawartością uranu w ziemi a poziomem radonu."]},{"cell_type":"code","metadata":{"id":"PpgL9x0ND7fM","colab_type":"code","colab":{}},"source":["# centrujemy zmienną aby lepiej zobaczyć wpływ jej odchyleń od średniej\n","u = np.log(data.Uppm)\n","u = u - np.mean(u)\n","print(u)\n","\n","with pm.Model() as hierarchical_intercept:\n","\n","    # Priors\n","    sigma_a = pm.HalfCauchy('sigma_a', 5)\n","\n","    # County uranium model for slope\n","    gamma_0 = pm.Normal('gamma_0', mu=0., sigma=1e5)\n","    gamma_1 = pm.Normal('gamma_1', mu=0., sigma=1e5)\n","\n","\n","    # Uranium model for intercept\n","    mu_a = gamma_0 + gamma_1*u\n","    # County variation not explained by uranium\n","    eps_a = pm.Normal('eps_a', mu=0, sigma=sigma_a, shape=n_counties)\n","    a = pm.Deterministic('a', mu_a + eps_a[data['county_code']])\n","\n","    # Common slope\n","    b = pm.Normal('b', mu=0., sigma=1e5)\n","\n","    # Model error\n","    sigma_y = pm.Uniform('sigma_y', lower=0, upper=100)\n","\n","    # Expected value\n","    y_hat = a + b * data['floor']\n","\n","    # Data likelihood\n","    y_like = pm.Normal('y_like', mu=y_hat, sigma=sigma_y, observed=data['log_radon'])\n","\n","    trace = pm.sample(2000, tune=2000, target_accept=.9)\n","\n","    pm.traceplot(trace,\n","                 var_names=['a', 'b', 'gamma_0', 'gamma_1', 'sigma_a'])\n","    display(pm.summary(trace, var_names=['b', 'gamma_0', 'gamma_1', 'sigma_a']))\n","\n","    pm.forestplot(trace, var_names=['b', 'gamma_0', 'gamma_1', 'sigma_a'])\n","\n","pm.model_to_graphviz(hierarchical_intercept)"],"execution_count":0,"outputs":[]}]}